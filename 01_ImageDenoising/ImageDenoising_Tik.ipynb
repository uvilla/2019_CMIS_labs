{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Denoising: Tikhonov regularization\n",
    "\n",
    "Given a possibly noisy image $d(\\boldsymbol{x}) \\in L^2(\\Omega)$ defined within a\n",
    "rectangular domain $\\Omega \\subset \\mathbb{R}^2$, we would like to\n",
    "find the image $m(\\boldsymbol{x}) \\in H^1(\\Omega)$ that is closest in the $L_2(\\Omega)$ sense, i.e. we\n",
    "want to minimize \n",
    "\n",
    "$$ \\mathcal{J}_{LS}(m) := \\frac{1}{2}\\int_\\Omega (m - d)^2 \\; d\\boldsymbol{x}, $$\n",
    "\n",
    "while also removing noise, which is assumed to comprise very *rough*\n",
    "components of the image.\n",
    "\n",
    "This latter goal can be incorporated as an\n",
    "additional term in the objective, in the form of a penalty, called regularization.\n",
    "\n",
    "Here we consider a Tikhonov regularization functional of the form\n",
    "\n",
    "$$ \\alpha \\mathcal{R}_{TN}(m) := \\! \\frac{\\alpha}{2}\\int_\\Omega \\nabla m\n",
    "\\cdot \\! \\nabla m \\; d\\boldsymbol{x}, $$\n",
    "\n",
    "where $\\alpha$ acts as a *diffusion* coefficient that controls\n",
    "how strongly we impose the penalty, i.e. how much smoothing\n",
    "occurs.\n",
    "\n",
    "Thus the denoised image $m \\in H^1(\\Omega)$ is the minimizer of the functional\n",
    "\n",
    "$$ \\mathcal{J}(m)  := \\mathcal{J}_{LS}(m) + \\alpha \\mathcal{R}_{TN}(m). $$\n",
    "\n",
    "## First order necessary optimality conditions\n",
    "\n",
    "Let $\\delta_m \\mathcal{J}(m, \\tilde{m})$ denote the first variation of $\\mathcal{J}(m)$ in the direction $\\tilde{m}$, i.e.\n",
    "\n",
    "$$\\delta_m \\mathcal{J}(m, \\tilde{m}) := \\lim_{\\varepsilon \\rightarrow 0} \\frac{\\mathcal{J}(m + \\varepsilon \\tilde{m}) - \\mathcal{J}(m)}{\\varepsilon} = \\left. \\frac{d}{d \\varepsilon} \\mathcal{J}(m + \\varepsilon \\tilde{m})\\right|_{\\varepsilon=0}.$$\n",
    "\n",
    "The necessary condition is that the first variation of $\\mathcal{J}(m)$ equals to $0$ for all directions $\\tilde{m} \\in H^1(\\Omega)$:\n",
    "\n",
    "$$ \\delta_m \\mathcal{J} = 0 \\Longleftrightarrow \\frac{d}{d \\varepsilon} \\mathcal{J}(m + \\varepsilon \\tilde{m}) = 0 \\quad \\forall \\tilde{m} \\in H^1(\\Omega).$$\n",
    "\n",
    "### Variational form:\n",
    "\n",
    "To obtain the variational form of the necessary optimality conditions we follow the steps below.\n",
    "\n",
    "1) Expand the one dimensional function $\\phi(\\varepsilon) := \\mathcal{J}(m + \\varepsilon \\tilde{m})$ as\n",
    "\n",
    "$$\\mathcal{J}(m + \\varepsilon \\tilde{m}) =\n",
    "\\frac{1}{2}\\int_\\Omega (m + \\varepsilon \\tilde{m} - d)^2 \\; d\\boldsymbol{x}\n",
    "+ \\frac{\\alpha}{2}\\int_\\Omega \\nabla (m +\\varepsilon \\tilde{m})\\cdot \\! \\nabla (m +\\varepsilon \\tilde{m}) \\; d\\boldsymbol{x}.$$\n",
    "\n",
    "2) Differentiate the one dimensional function $\\phi(\\varepsilon)$ with respect to $\\varepsilon$\n",
    "\n",
    "$$ \\frac{d \\phi}{d \\varepsilon} = \n",
    "\\int_\\Omega \\tilde{m} (m + \\varepsilon \\tilde{m} - d) \\; d\\boldsymbol{x}\n",
    "+ \\alpha\\int_\\Omega \\nabla \\tilde{m} \\cdot \\! \\nabla (m +\\varepsilon \\tilde{m}) \\; d\\boldsymbol{x}.\n",
    "$$\n",
    "\n",
    "3) Evaluate $\\frac{d \\phi}{d \\varepsilon}$ at $\\varepsilon = 0$\n",
    "\n",
    "$$ \\delta_m \\mathcal{J}(m, \\tilde{m}) = \\left. \\frac{d \\phi}{d \\varepsilon} \\right|_{\\varepsilon=0} = \n",
    "\\int_\\Omega \\tilde{m} (m - d) \\; d\\boldsymbol{x}\n",
    "+ \\alpha\\int_\\Omega \\nabla \\tilde{m} \\cdot \\! \\nabla m \\; d\\boldsymbol{x}.$$\n",
    "\n",
    "4) Set $\\delta_m \\mathcal{J}(m, \\tilde{m}) = 0$ for all $\\tilde{m} \\in H^1(\\Omega)$. That is find $m \\in H^1(\\Omega)$ such that:\n",
    "\n",
    "$$\n",
    "\\int_\\Omega \\tilde{m} (m - d) \\; d\\boldsymbol{x}\n",
    "+ \\alpha\\int_\\Omega \\nabla \\tilde{m} \\cdot \\! \\nabla m \\; d\\boldsymbol{x} = 0 \\quad \\forall \\tilde{m} \\in H^1(\\Omega).\n",
    "$$\n",
    "\n",
    "### Strong form:\n",
    "\n",
    "To obtain the strong form, we invoke Green's first identity and write\n",
    "\n",
    "$$ \\alpha\\int_\\Omega \\nabla \\tilde{m} \\cdot \\! \\nabla m \\; d\\boldsymbol{x} =\n",
    "-\\alpha\\int_\\Omega \\tilde{m} \\nabla \\cdot (\\nabla m) \\; d\\boldsymbol{x}\n",
    "+ \\int_{\\partial\\Omega} \\tilde{m} (\\nabla m \\cdot \\boldsymbol{n}) d\\boldsymbol{x}, $$\n",
    "\n",
    "where $\\boldsymbol{n}$ is the outward unit normal vector to $\\partial\\Omega$.\n",
    "\n",
    "By linearity of the integral we have\n",
    "\n",
    "$$ \\int_\\Omega \\tilde{m} (-\\alpha \\nabla \\cdot (\\nabla m) + m - d) \\; d\\boldsymbol{x} \n",
    "+ \\int_{\\partial\\Omega} \\tilde{m} (\\nabla m \\cdot \\boldsymbol{n}) d\\boldsymbol{x} = 0 \\quad \\forall \\tilde{m}.$$\n",
    "\n",
    "Assuming that $d$ is smooth enough, by arbitrarity of $\\tilde{m} \\in H^1(\\Omega)$, the strong form the first order optimality conditions reads\n",
    "\n",
    "$$ \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "- \\nabla \\cdot (\\alpha \\nabla m) + m = d, & {\\rm in} \\; \\Omega;\\\\\n",
    "(\\alpha \\nabla m) \\cdot \\boldsymbol{n} = 0, & {\\rm on} \\; \\partial\\Omega.\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "The expression above corresponds to a boundary value problem with homogeneous Neumann condition \n",
    "$\\nabla m \\cdot \\boldsymbol{n}=0$ on the boundary of $\\Omega$,\n",
    "which amounts to assuming that the image intensity does not change\n",
    "normal to the boundary of the image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Python imports\n",
    "\n",
    "We import the following libraries:\n",
    "\n",
    "- `math`, which contains several mathematical functions\n",
    "- `matplotlib, numpy, scipy`, three libraries that together allow similar functionalities to matlab\n",
    "- `dolfin`, which allows us to discretize and solve variational problems using the finite element method\n",
    "- `hippylib`, the extesible framework I created to solve inverse problems in Python\n",
    "\n",
    "Finally, we import the `logging` library to silence most of the output produced by `dolfin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "import dolfin as dl\n",
    "\n",
    "import hippylib as hp\n",
    "from hippylib import nb\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger('FFC').setLevel(logging.WARNING)\n",
    "logging.getLogger('UFL').setLevel(logging.WARNING)\n",
    "dl.set_log_active(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Geometry, true image, and data.\n",
    "\n",
    "1. Read the true image from file, store the pixel values in `data`. \n",
    "\n",
    "2. The width of the image is `Lx = 1` and height `Ly` is set such that the aspect ratio of the image is preserved.\n",
    "\n",
    "3. Generate a triangulation (pixelation) `mesh` of the region of interest.\n",
    "\n",
    "4. Define the finite element space `V` of piecewise linear function on the elements of `mesh`. This represent the space of discretized images.\n",
    "\n",
    "5. Interpolate the true image in the discrete space `V`. Call this interpolation `m_true`.\n",
    "\n",
    "6. Corrupt the true image with i.i.d. Gaussian noise ($\\sigma^2 = 0.09$) and interpolated the noisy image in the discrete space `V`. Call this interpolation `d`.\n",
    "\n",
    "7. Visualize the true image `m_true` and the noisy image `d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('circles.mat')['im']\n",
    "\n",
    "Lx = 1.\n",
    "h = Lx/float(data.shape[0])\n",
    "Ly = float(data.shape[1])*h\n",
    "  \n",
    "mesh = dl.RectangleMesh(dl.Point(0,0),dl.Point(Lx,Ly),data.shape[0], data.shape[1])\n",
    "V = dl.FunctionSpace(mesh, \"Lagrange\",1)\n",
    "\n",
    "trueImage = hp.NumpyScalarExpression2D()\n",
    "trueImage.setData(data, h, h)\n",
    "m_true  = dl.interpolate(trueImage, V)\n",
    "\n",
    "np.random.seed(seed=1)\n",
    "noise_std_dev = .3\n",
    "noise = noise_std_dev*np.random.randn(data.shape[0], data.shape[1])\n",
    "noisyImage = hp.NumpyScalarExpression2D()\n",
    "noisyImage.setData(data+noise, h, h)\n",
    "d = dl.interpolate(noisyImage, V)\n",
    "\n",
    "# Get min/max of noisy image, so that we can show all plots in the same scale\n",
    "vmin = np.min(d.vector().get_local())\n",
    "vmax = np.max(d.vector().get_local())\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "nb.plot(m_true, subplot_loc=121, mytitle=\"True Image\", vmin=vmin, vmax = vmax)\n",
    "nb.plot(d, subplot_loc=122, mytitle=\"Noisy Image\", vmin=vmin, vmax = vmax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define misfit and regurization functionals and their variations.\n",
    "\n",
    "Here we describe the variational forms for the $L_2$ misfit functional\n",
    "\n",
    "$$ \\mathcal{J}_{LS}(m) := \\frac{1}{2}\\int_\\Omega (m - d)^2 \\; d\\boldsymbol{x}, $$\n",
    "\n",
    "and the Tikhonov regularization functional\n",
    "\n",
    "$$ \\mathcal{R}_{TN}(m) := \\! \\frac{1}{2}\\int_\\Omega \\nabla m\n",
    "\\cdot \\! \\nabla m \\; d\\boldsymbol{x} $$\n",
    "\n",
    "By letting $\\alpha > 0$ be the amount of regularization, the Tikhonov regularized functional $\\mathcal{J}$ reads  \n",
    "\n",
    "$$ \\mathcal{J}(m) = \\mathcal{J}_{LS}(m) + \\alpha \\mathcal{R}_{TN}(m) = \\frac{1}{2}\\int_\\Omega (m - d)^2 \\; d\\boldsymbol{x} + \\frac{\\alpha}{2}\\int_\\Omega \\nabla m \\cdot \\nabla m d\\boldsymbol{x}.$$\n",
    "\n",
    "The first variation of $\\mathcal{J}$ is given by\n",
    "\n",
    "$$ \\delta_m \\mathcal{J}(m, \\tilde{m}) = \\int_\\Omega \\tilde{m} (m - d) \\; d\\boldsymbol{x}\n",
    "+ \\alpha\\int_\\Omega \\nabla \\tilde{m} \\cdot \\! \\nabla m \\; d\\boldsymbol{x}.$$\n",
    "\n",
    "Since we also know the true image `m_true` (*this will not be the case for real applications*),\n",
    "we can also compute the true $L_2$ error functional (mean square error MSE)L\n",
    "\n",
    "$$ {\\rm MSE}(m) := \\frac{1}{2}\\int_\\Omega (m - m_{\\rm true})^2 \\; d\\boldsymbol{x}. $$\n",
    "\n",
    "In the code below:\n",
    "\n",
    "- `m = dl.Function(V)` indicates the reconstructed image\n",
    "- `m_tilde = dl.TestFunction(V)` is a place holder for the arbitrary direction $\\tilde{m}$\n",
    "- The function `dl.solve(grad==0, m)` solves the (possibly nonlinear) system of equations to set the first variation of $\\mathcal{J}$ to $0$.\n",
    "- The function `dl.assemble(form)` evaluates the variational form `form`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TNsolution(alpha):\n",
    "    m = dl.Function(V)\n",
    "    m_tilde = dl.TestFunction(V)\n",
    "    \n",
    "    J_ls = dl.Constant(.5)*dl.inner(m - d, m - d)*dl.dx\n",
    "    R_tn = dl.Constant(.5)*dl.inner(dl.grad(m), dl.grad(m))*dl.dx\n",
    "    J = J_ls + dl.Constant(alpha)*R_tn\n",
    "    \n",
    "    grad = dl.inner(m - d, m_tilde)*dl.dx + dl.Constant(alpha)*dl.inner(dl.grad(m), dl.grad(m_tilde))*dl.dx\n",
    "     \n",
    "    dl.solve(grad==0, m)\n",
    "    \n",
    "    MSE = dl.inner(m - m_true, m - m_true)*dl.dx\n",
    "    \n",
    "    print( \"{0:15e} {1:15e} {2:15e} {3:15e} {4:15e}\".format(\n",
    "           alpha, dl.assemble(J), dl.assemble(J_ls), dl.assemble(R_tn), dl.assemble(MSE)) )\n",
    "    \n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reconstruction for different values of $\\alpha$.\n",
    "\n",
    "We define some values of $\\alpha$ ($\\alpha = 10^{-1}, 10^{-2}, 10^{-3}, 10^{-4}, 10^{-5}$) for the choice of the regularization paramenter.\n",
    "\n",
    "Using the MSE as measure of image quality, the best reconstruction of the original image is obtained for $\\alpha = 10^{-4}$. However, we could also use Morzov discrepancy principle or the L-curve to find a good choice of $\\alpha$.\n",
    "\n",
    "By looking at the reconstructed image, we notice that the sharp edges of the true image are a bit blurred in the reconstruction. This is one of the main shortcoming of Tikhonov regularization: more advanced types of regularization (like total variation regularization) should be used to better preserve edges in the reconstructed solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphas = 5\n",
    "alphas = np.power(10., -np.arange(1, n_alphas+1))\n",
    "\n",
    "print( \"{0:15} {1:15} {2:15} {3:15} {4:15}\".format(\"alpha\", \"J\", \"J_ls\", \"R_tn\", \"MSE\") )\n",
    "for alpha in alphas:\n",
    "    m = TNsolution(alpha)\n",
    "    plt.figure()\n",
    "    nb.plot(m, vmin=vmin, vmax = vmax, mytitle=\"alpha = {0:1.2e}\".format(alpha))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Copyright &copy; 2019-2020, Washington University in St. Louis.\n",
    "\n",
    "All Rights reserved.\n",
    "See file COPYRIGHT for details.\n",
    "\n",
    "This file is part of **cmis_labs**, the teaching material for  ESE 5932 *Computational Methods for Imaging Science* at Washington University in St. Louis. Please see [https://uvilla.github.io/cmis_labs](https://uvilla.github.io/cmis_labs) for more information and source code availability.\n",
    "\n",
    "We would like to acknowledge the Extreme Science and Engineering Discovery Environment (XSEDE), which is supported by National Science Foundation grant number ACI-1548562, for providing cloud computing resources (Jetstream) for this course through allocation TG-SEE190001."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
